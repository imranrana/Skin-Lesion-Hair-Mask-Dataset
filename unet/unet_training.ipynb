{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T13:26:29.565859Z",
     "iopub.status.busy": "2021-09-16T13:26:29.565387Z",
     "iopub.status.idle": "2021-09-16T13:26:31.012050Z",
     "shell.execute_reply": "2021-09-16T13:26:31.010997Z",
     "shell.execute_reply.started": "2021-09-16T13:26:29.565800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from model import build_unet\n",
    "from metrics import dice_coef, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T13:26:33.949216Z",
     "iopub.status.busy": "2021-09-16T13:26:33.948657Z",
     "iopub.status.idle": "2021-09-16T13:26:33.975636Z",
     "shell.execute_reply": "2021-09-16T13:26:33.974153Z",
     "shell.execute_reply.started": "2021-09-16T13:26:33.949155Z"
    }
   },
   "outputs": [],
   "source": [
    "H = 512\n",
    "W = 512\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "def load_data(dataset_path, split=0.1):\n",
    "    images = sorted(glob(os.path.join(dataset_path, 'dermoscopic_image', \"*.png\")))\n",
    "    masks = sorted(glob(os.path.join(dataset_path, 'mask', \"*.png\")))\n",
    "\n",
    "    test_size = int(len(images) * split)\n",
    "\n",
    "    train_x, valid_x = train_test_split(images, test_size=test_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=test_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)  \n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x                             \n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  \n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)                    \n",
    "    x = np.expand_dims(x, axis=-1)            \n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return 1 - numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T13:26:36.096698Z",
     "iopub.status.busy": "2021-09-16T13:26:36.096097Z",
     "iopub.status.idle": "2021-09-16T13:47:59.503717Z",
     "shell.execute_reply": "2021-09-16T13:47:59.502337Z",
     "shell.execute_reply.started": "2021-09-16T13:26:36.096635Z"
    }
   },
   "outputs": [],
   "source": [
    "#seeding\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#folder for saving data\n",
    "create_dir(\"files\")\n",
    "\n",
    "#hyperparameters\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "num_epoch = 1000\n",
    "model_path = \"files/model.h5\"\n",
    "csv_path = \"files/data.csv\"\n",
    "\n",
    "#dataset\n",
    "dataset_path = '...' #provide path to the dataset parent folder with dermoscopic images and masks in dermoscopic_image and mask sub-folders\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n",
    "\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
    "print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "train_dataset = tf_dataset(train_x, train_y, batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch_size)\n",
    "\n",
    "train_steps = len(train_x)//batch_size\n",
    "valid_steps = len(valid_x)//batch_size\n",
    "\n",
    "if len(train_x) % batch_size != 0:\n",
    "    train_steps += 1\n",
    "\n",
    "if len(valid_x) % batch_size != 0:\n",
    "    valid_steps += 1\n",
    "\n",
    "#model\n",
    "model = build_unet((H, W, 3))\n",
    "metrics = [dice_coef, iou, Recall(), Precision()]\n",
    "model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    CSVLogger(csv_path),\n",
    "    TensorBoard(),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]\n",
    "\n",
    "#training\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
